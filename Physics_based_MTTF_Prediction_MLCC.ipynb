{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmsS1JYFI9DCRzM/xdXefH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HpIUM-OsiBJ-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import itertools\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set_theme('poster')\n",
        "sns.set(style='ticks', font_scale=2)\n",
        "mpl.rcParams['font.weight'] = 'bold'\n",
        "mpl.rcParams.update({'text.usetex': False})\n",
        "\n",
        "random_seed = 42\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "with open('Data.csv', 'r') as f:\n",
        "    exp_df = pd.read_csv(f)\n",
        "    exp_df['MTTF'] = np.log(exp_df['MTTF'])\n",
        "\n",
        "info_dict = {'135':(9.42, 19.03), '140':(9.78, 18.58), '150':(9.14, 17.05)}\n",
        "n_dict = {'135':6.35, '140':6.3, '150':7.15}\n",
        "T_list = [135, 140, 150]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(df_orig):\n",
        "    df = df_orig.copy()\n",
        "    df['V'] = df_orig['V']\n",
        "    df['T'] = df_orig['T']\n",
        "    df['V2'] = df['V'].apply(lambda x: x**2)\n",
        "    df['V4'] = df['V'].apply(lambda x: x**4)\n",
        "    df['V*T'] = df['V'] * df['T']\n",
        "    df['V/T'] = df['V'] / df['T']\n",
        "    df['LnV'] = df['V'].apply(lambda x: math.log(x))\n",
        "    df['LnT'] = df['T'].apply(lambda x: math.log(x))\n",
        "    df['TLnV'] = df['T'] * df['LnV']\n",
        "    df['VLnT'] = df['V'] * df['LnT']\n",
        "    return df\n",
        "\n",
        "def get_TPM_MTTF(V, T, Beta, C):\n",
        "    T += 273.15\n",
        "    MTTF = np.exp(C-np.log(np.sinh(Beta*V/T)))/3600\n",
        "    return MTTF\n",
        "\n",
        "def generate_TPM_dataset(T, Beta, C):\n",
        "    Vs, MTTFs = [], []\n",
        "    for V in np.linspace(200, 400, 101):\n",
        "        MTTF = get_TPM_MTTF(V, T, Beta, C)\n",
        "        MTTFs.append(MTTF)\n",
        "        Vs.append(V)\n",
        "    df = pd.DataFrame()\n",
        "    df['V'] = Vs\n",
        "    df['T'] = [T] * len(Vs)\n",
        "    df = get_features(df)\n",
        "    df['MTTF'] = MTTFs\n",
        "    return df\n",
        "\n",
        "def rmspe(y_true, y_pred):\n",
        "    if isinstance(y_true, pd.Series):\n",
        "        y_true = y_true.to_numpy()\n",
        "    if isinstance(y_pred, pd.Series):\n",
        "        y_pred = y_pred.to_numpy()\n",
        "\n",
        "    if len(y_true) != len(y_pred):\n",
        "        raise ValueError(\"Input arrays must have the same length.\")\n",
        "\n",
        "    percentage_errors = ((y_true - y_pred) / y_true) ** 2\n",
        "    rmspe_value = np.sqrt(np.mean(percentage_errors))\n",
        "    return rmspe_value\n",
        "\n",
        "def rse(y_true, y_pred):\n",
        "    if isinstance(y_true, pd.Series):\n",
        "        y_true = y_true.to_numpy()\n",
        "    if isinstance(y_pred, pd.Series):\n",
        "        y_pred = y_pred.to_numpy()\n",
        "\n",
        "    if len(y_true) != len(y_pred):\n",
        "        raise ValueError(\"Input arrays must have the same length.\")\n",
        "\n",
        "    numerator = np.sum((y_true - y_pred) ** 2)\n",
        "    denominator = np.sum((y_true - np.mean(y_true)) ** 2)\n",
        "    rse = numerator / denominator\n",
        "    return rse\n",
        "\n",
        "def get_Ea(df1, df2):\n",
        "    Ea_list = []\n",
        "    Kb = 8.617e-5\n",
        "    for _, row1 in df1.iterrows():\n",
        "        for _, row2 in df2.iterrows():\n",
        "            T1 = row1.iloc[1] + 273.15\n",
        "            T2 = row2.iloc[1] + 273.15\n",
        "            V1 = row1.iloc[0]\n",
        "            V2 = row2.iloc[0]\n",
        "            t1 = np.exp(row1.iloc[-4])\n",
        "            t2 = np.exp(row2.iloc[-4])\n",
        "            if V1 == V2:\n",
        "                Ea = np.log(t1/t2)*Kb/(1/T1 - 1/T2)\n",
        "                Ea_list.append(Ea)\n",
        "    Ea = np.average(Ea_list)\n",
        "    return Ea\n",
        "\n",
        "\n",
        "\n",
        "def train_base_model(data):\n",
        "    params = {\n",
        "        \"learning_rate\": [0.01, 0.1],\n",
        "        \"max_depth\": [3, 4],\n",
        "        \"n_estimators\": [100, 200]}\n",
        "    \n",
        "    model = xgb.XGBRegressor(objective='reg:squarederror')\n",
        "    cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
        "\n",
        "    X = data.iloc[:,:-1]\n",
        "    y = data.iloc[:, -1]\n",
        "    grid_search = GridSearchCV(model, params, cv=cv, scoring=\"neg_mean_squared_error\")\n",
        "    grid_search.fit(X, y)\n",
        "    best_params = grid_search.best_params_\n",
        "\n",
        "    model = xgb.XGBRegressor(objective='reg:squarederror')\n",
        "    model.set_params(**best_params)\n",
        "    model.fit(X, y)\n",
        "    return model, best_params\n",
        "\n",
        "def train_transferred_model(data, model, best_params):\n",
        "    transferred_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
        "    transferred_model.set_params(**best_params)\n",
        "    X = data.iloc[:,:-1]\n",
        "    y = data.iloc[:, -1]\n",
        "    transferred_model.fit(X, y, xgb_model = model)\n",
        "    return transferred_model"
      ],
      "metadata": {
        "id": "yWBeQ9g5zdxF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = get_features(exp_df)\n",
        "df = df[['V', 'T', 'V2', 'V4', 'V*T', 'V/T', 'LnV', 'LnT', 'TLnV', 'VLnT', 'MTTF', 'n', 'Beta', 'C']]\n",
        "results_dict = {}\n",
        "\n",
        "for T in T_list:\n",
        "    exp_results, ml_results, tpm_results, Vs, Ts = [], [], [], [], []\n",
        "    df_base = df[df['T'] == T].reset_index(drop=True)\n",
        "    for index, row in df_base.iterrows():\n",
        "        Ts.append(T)\n",
        "        V0 = row.iloc[0]\n",
        "        Vs.append(V0)\n",
        "        Beta = row.iloc[-2]\n",
        "        C = row.iloc[-1]\n",
        "        yhat_exp = row.iloc[-4]\n",
        "        df_TPM = generate_TPM_dataset(T, Beta, C)\n",
        "        df_TPM['MTTF'] = np.log(df_TPM['MTTF'])\n",
        "        base_model, best_params = train_base_model(df_TPM)\n",
        "        df_transfer = df_base.drop(index = index).reset_index(drop=True).iloc[:, :-3]\n",
        "        transferred_model = train_transferred_model(df_transfer, base_model, best_params)\n",
        "        yhat_ml = transferred_model.predict(pd.DataFrame(row.iloc[:-4]).T)\n",
        "        yhat_tpm = get_TPM_MTTF(V0, T, Beta, C)\n",
        "        exp_results.append(np.exp(yhat_exp))\n",
        "        ml_results.append(np.exp(yhat_ml[0]))\n",
        "        tpm_results.append(yhat_tpm)\n",
        "    results_dict[str(T)] = pd.DataFrame({'V': Vs, 'T': Ts, 'MLM':ml_results, 'TPM':tpm_results, 'Experiment': exp_results})\n",
        "\n",
        "for T in T_list:\n",
        "    df_base = df[df['T'] == T].reset_index(drop=True)\n",
        "    em_results = []\n",
        "    for index, row in df_base.iterrows():\n",
        "        n = row.iloc[-3]\n",
        "        rem_df = df_base.drop(index = index).reset_index(drop=True)\n",
        "        V0 = row.iloc[0]\n",
        "        random_row = rem_df.sample(n=1)\n",
        "        V1 = random_row.iloc[:,0]\n",
        "        mttf1 = np.exp(random_row.iloc[:, -4])\n",
        "        mttf0 = mttf1/((V0/V1) ** n)\n",
        "        em_results.append(mttf0)\n",
        "    results_dict[str(T)]['EM'] = [x.iloc[0] for x in em_results]\n",
        "\n",
        "\n",
        "rmse_scores_ml, rmse_scores_tpm, rmse_scores_em, rmspe_scores_ml, rmspe_scores_tpm, rmspe_scores_em = [], [], [], [], [], []\n",
        "Ts = []\n",
        "for T in T_list:\n",
        "    Ts.append(T)\n",
        "    plot_df = results_dict[str(T)]\n",
        "    Vs = plot_df['V']\n",
        "    tpm_results = plot_df['TPM']\n",
        "    ml_results = plot_df['MLM']\n",
        "    em_results = plot_df['EM']\n",
        "    true_results = plot_df['Experiment']\n",
        "    rmspe_tpm = rmspe(true_results, tpm_results)\n",
        "    rmspe_ml = rmspe(true_results, ml_results)\n",
        "    rmspe_em = rmspe(true_results, em_results)\n",
        "    rmse_tpm = mean_squared_error(true_results, tpm_results) ** 0.5\n",
        "    rmse_ml = mean_squared_error(true_results, ml_results) ** 0.5\n",
        "    rmse_em = mean_squared_error(true_results, em_results) ** 0.5\n",
        "    rmse_scores_ml.append(rmse_ml)\n",
        "    rmse_scores_tpm.append(rmse_tpm)\n",
        "    rmse_scores_em.append(rmse_em)\n",
        "    rmspe_scores_ml.append(rmspe_ml)\n",
        "    rmspe_scores_tpm.append(rmspe_tpm)\n",
        "    rmspe_scores_em.append(rmspe_em)\n",
        "    fig, ax = plt.subplots(figsize=(10,10), dpi=300)\n",
        "    ax.plot(Vs, true_results, label='Experiment', linestyle=':', marker='^', markersize=15, linewidth=3)\n",
        "    ax.plot(Vs, em_results, label = 'EM', linestyle=':', marker='P', markersize=15, linewidth=3)\n",
        "    ax.plot(Vs, tpm_results, label = 'TPM', linestyle=':', marker='o', markersize=15, linewidth=3)\n",
        "    ax.plot(Vs, ml_results, label = 'MLM', linestyle=':', marker='s', markersize=15, linewidth=3)\n",
        "    \n",
        "    \n",
        "    ax.set_xlabel('V (v)', fontsize=25, fontweight='bold')\n",
        "    ax.set_ylabel('MTTF (hr)', fontsize=25, fontweight='bold')\n",
        "    ax.set_title('Model performance for T = {}°C'.format(T), fontsize=25, fontweight='bold')\n",
        "    ax.legend(frameon=False)\n",
        "    # ax.text(0.6, 0.7, f'$RMSE_{{EM}}$: {round(rmse_em, 2)}\\n$RMSE_{{TPM}}$: {round(rmse_tpm, 2)}\\n$RMSE_{{MLM}}$: {round(rmse_ml, 2)}',\n",
        "    #          ha='left', va='top',transform=plt.gca().transAxes)\n",
        "    ax.spines['top'].set_visible(True)\n",
        "    ax.spines['right'].set_visible(True)\n",
        "    ax.spines['bottom'].set_visible(True)\n",
        "    ax.spines['left'].set_visible(True)\n",
        "    ax = plt.gca()\n",
        "    yticks = ax.get_yticks()\n",
        "\n",
        "    if 0 not in yticks:\n",
        "        yticks = np.append(0, yticks)\n",
        "    ax.minorticks_off()\n",
        "    ax.tick_params(axis='both', which='major', direction='in', length=10, width=2)\n",
        "    # fig.savefig(f\"{T}.tiff\", dpi=300)\n",
        "    # fig.savefig(f\"{T}.eps\", dpi=300)\n",
        "\n",
        "scores = {'T':Ts, 'RMSE_TPM':rmse_scores_tpm, 'RMSE_EM': rmse_scores_em, 'RMSE_MLM':rmse_scores_ml, 'RMSPE_TPM':rmspe_scores_tpm, 'RMSPE_EM': rmspe_scores_em, 'RMSPE_MLM':rmspe_scores_ml}\n",
        "scores = pd.DataFrame(scores)"
      ],
      "metadata": {
        "id": "G40kSrXFWm4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T_perms = list(itertools.permutations(T_list, 3))\n",
        "Kb = 8.617e-5\n",
        "T3_results_dict = {'135':pd.DataFrame(), '140':pd.DataFrame(), '150':pd.DataFrame()}\n",
        "\n",
        "for T1, T2, T3 in T_perms:\n",
        "    df1 = df[df['T']==T1]\n",
        "    df2 = df[df['T']==T2]\n",
        "    df3 = df[df['T']==T3]\n",
        "    df12 = pd.concat((df1, df2)).reset_index(drop=True).iloc[:, :-3]\n",
        "    Ea = get_Ea(df1, df2)\n",
        "    Beta1, C1 = info_dict[str(T1)]\n",
        "    Beta2, C2 = info_dict[str(T2)]\n",
        "    df_TPM1 = generate_TPM_dataset(T1, Beta1, C1)\n",
        "    df_TPM2 = generate_TPM_dataset(T2, Beta2, C2)\n",
        "    df_TPM = pd.concat((df_TPM1, df_TPM2)).reset_index(drop=True)\n",
        "    df_TPM['MTTF'] = np.log(df_TPM['MTTF'])\n",
        "    base_model, best_params = train_base_model(df_TPM)\n",
        "    transferred_model1 = train_transferred_model(df12, base_model, best_params)\n",
        "\n",
        "    Vs, Ts, ts = [], [], []\n",
        "    for _, row in df12.iterrows():\n",
        "        T4 = row.iloc[1] + 273.15\n",
        "        exp_coeff = np.exp(Ea/Kb*(1/T4-1/(T3+273.15)))\n",
        "        V4 = row.iloc[0]\n",
        "        V3 = V4\n",
        "        t4 = np.exp(row.iloc[-1])\n",
        "        t3 = t4/exp_coeff\n",
        "        Vs.append(V3)\n",
        "        Ts.append(T3)\n",
        "        ts.append(t3)\n",
        "\n",
        "    df_finetune = pd.DataFrame({'V':Vs, 'T':Ts, 'MTTF':ts})\n",
        "    df_finetune.drop_duplicates(subset='V', keep='first', inplace=True)\n",
        "    df_finetune = df_finetune.sort_values(by='V')\n",
        "    df_finetune['MTTF'] = np.log(df_finetune['MTTF'])\n",
        "    df_finetune = get_features(df_finetune)\n",
        "    df_finetune = df_finetune[['V', 'T', 'V2', 'V4', 'V*T', 'V/T', 'LnV', 'LnT', 'TLnV', 'VLnT', 'MTTF']]\n",
        "    transferred_model2 = train_transferred_model(df_finetune, transferred_model1, best_params)\n",
        "\n",
        "    yhat_ml = np.exp(transferred_model2.predict(df3.iloc[:, :-4]))\n",
        "    T3_results_dict[str(T3)]['MLM'] = yhat_ml\n",
        "    yhat_exp = np.exp(df3.iloc[:, -4])\n",
        "    T3_results_dict[str(T3)]['Experiment'] = list(yhat_exp)\n",
        "    n = n_dict[str(T3)]\n",
        "    \n",
        "    shared_vs = set(sorted(Vs))\n",
        "    yhat_em = []\n",
        "    for v in df3.iloc[:, 0]:\n",
        "        if v in shared_vs:\n",
        "            indices = np.where(df12['V'] == v)\n",
        "            first_idx = indices[0][0]\n",
        "            row = df12.loc[first_idx]\n",
        "            V0 = row.iloc[0]\n",
        "            T0 = row.iloc[1]\n",
        "            V1 = V0\n",
        "            mttf0 = np.exp(row.iloc[-1])\n",
        "            mttf3 = mttf0 * np.exp(Ea/Kb*(1/(T3+273.15) - 1/(T0+273.15)))\n",
        "        else:\n",
        "            random_row = df12.sample(n=1)\n",
        "            V0 = random_row.iloc[:, 0]\n",
        "            T0 = random_row.iloc[:, 1]\n",
        "            V1 = V0\n",
        "            mttf0 = np.exp(random_row.iloc[:, -4])\n",
        "            mttf3 = mttf0 * (V0/V1) ** n * np.exp(Ea/Kb*(1/(T3+273.15) - 1/(T0+273.15)))\n",
        "            mttf3 = mttf3.iloc[0]\n",
        "\n",
        "        yhat_em.append(mttf3)\n",
        "    \n",
        "    T3_results_dict[str(T3)]['EM'] = yhat_em\n",
        "    T3_results_dict[str(T3)]['V'] = list(df3.iloc[:, 0])\n",
        "\n",
        "rmse_scores_ml, rmse_scores_em, rmspe_scores_ml, rmspe_scores_em = [], [], [], []\n",
        "Ts = []\n",
        "for T in T_list:\n",
        "    Ts.append(T)\n",
        "    plot_df = T3_results_dict[str(T)]\n",
        "    Vs = plot_df['V']\n",
        "    ml_results = plot_df['MLM']\n",
        "    em_results = plot_df['EM']\n",
        "    true_results = plot_df['Experiment']\n",
        "    rmspe_ml = rmspe(true_results, ml_results)\n",
        "    rmspe_em = rmspe(true_results, em_results)\n",
        "    rmse_ml = mean_squared_error(true_results, ml_results) ** 0.5\n",
        "    rmse_em = mean_squared_error(true_results, em_results) ** 0.5\n",
        "    rmse_scores_ml.append(rmse_ml)\n",
        "    rmse_scores_em.append(rmse_em)\n",
        "    rmspe_scores_ml.append(rmspe_ml)\n",
        "    rmspe_scores_em.append(rmspe_em)\n",
        "    fig, ax = plt.subplots(figsize=(10,10), dpi=300)\n",
        "    ax.plot(Vs, true_results, label='Experiment', linestyle=':', marker='^', markersize=15, linewidth=3)\n",
        "    ax.plot(Vs, ml_results, label = 'MLM', linestyle=':', marker='s', markersize=15, linewidth=3)\n",
        "    ax.plot(Vs, em_results, label = 'EM', linestyle=':', marker='P', markersize=15, linewidth=3)\n",
        "    \n",
        "    \n",
        "    \n",
        "    ax.set_xlabel('V (v)', fontsize=25, fontweight='bold')\n",
        "    ax.set_ylabel('MTTF (hr)', fontsize=25, fontweight='bold')\n",
        "    ax.set_title(r'Model performance for T = {}°C'.format(T), fontsize=25, fontweight='bold')\n",
        "    ax.legend(frameon=False)\n",
        "    # ax.text(0.6, 0.7, f'$RMSE_{{EM}}$: {round(rmse_em, 2)}\\n$RMSE_{{TPM}}$: {round(rmse_tpm, 2)}\\n$RMSE_{{MLM}}$: {round(rmse_ml, 2)}',\n",
        "    #          ha='left', va='top',transform=plt.gca().transAxes)\n",
        "    ax.spines['top'].set_visible(True)\n",
        "    ax.spines['right'].set_visible(True)\n",
        "    ax.spines['bottom'].set_visible(True)\n",
        "    ax.spines['left'].set_visible(True)\n",
        "    ax = plt.gca()\n",
        "    yticks = ax.get_yticks()\n",
        "\n",
        "    if 0 not in yticks:\n",
        "        yticks = np.append(0, yticks)\n",
        "    ax.minorticks_off()\n",
        "    ax.tick_params(axis='both', which='major', direction='in', length=10, width=2)\n",
        "    fig.savefig(f\"{T}.tiff\", dpi=300)\n",
        "    fig.savefig(f\"{T}.eps\", dpi=300)\n",
        "\n",
        "scores = {'T':Ts, 'RMSE_EM': rmse_scores_em, 'RMSE_MLM':rmse_scores_ml, 'RMSPE_EM': rmspe_scores_em, 'RMSPE_MLM':rmspe_scores_ml}\n",
        "scores = pd.DataFrame(scores)"
      ],
      "metadata": {
        "id": "oecFI87iuPEl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}